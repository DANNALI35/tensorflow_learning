{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 示例：RNN手写数字识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/chineseNER/jupyter/Tensorflow入门/dataset/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /home/chineseNER/jupyter/Tensorflow入门/dataset/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/chineseNER/jupyter/Tensorflow入门/dataset/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/chineseNER/jupyter/Tensorflow入门/dataset/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.set_random_seed(35)\n",
    "mnist = input_data.read_data_sets('/home/chineseNER/jupyter/Tensorflow入门/dataset/MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、数据观察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入数据的shape:\n",
      "(55000, 784)\n",
      "输入数据:\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "单张图片输入数据:\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.38039219  0.37647063\n",
      "  0.3019608   0.46274513  0.2392157   0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.35294119  0.5411765\n",
      "  0.92156869  0.92156869  0.92156869  0.92156869  0.92156869  0.92156869\n",
      "  0.98431379  0.98431379  0.97254908  0.99607849  0.96078438  0.92156869\n",
      "  0.74509805  0.08235294  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.54901963  0.98431379  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.99607849  0.99607849  0.74117649  0.09019608\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.88627458  0.99607849  0.81568635\n",
      "  0.78039223  0.78039223  0.78039223  0.78039223  0.54509807  0.2392157\n",
      "  0.2392157   0.2392157   0.2392157   0.2392157   0.50196081  0.8705883\n",
      "  0.99607849  0.99607849  0.74117649  0.08235294  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.14901961  0.32156864  0.0509804   0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.13333334  0.83529419  0.99607849  0.99607849  0.45098042  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.32941177  0.99607849  0.99607849  0.91764712  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.32941177  0.99607849  0.99607849  0.91764712  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.41568631  0.6156863   0.99607849  0.99607849  0.95294124  0.20000002\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.09803922  0.45882356  0.89411771\n",
      "  0.89411771  0.89411771  0.99215692  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.94117653  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.26666668  0.4666667   0.86274517\n",
      "  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.99607849  0.55686277  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.14509805  0.73333335  0.99215692\n",
      "  0.99607849  0.99607849  0.99607849  0.87450987  0.80784321  0.80784321\n",
      "  0.29411766  0.26666668  0.84313732  0.99607849  0.99607849  0.45882356\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.44313729\n",
      "  0.8588236   0.99607849  0.94901967  0.89019614  0.45098042  0.34901962\n",
      "  0.12156864  0.          0.          0.          0.          0.7843138\n",
      "  0.99607849  0.9450981   0.16078432  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.66274512  0.99607849  0.6901961   0.24313727  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.18823531\n",
      "  0.90588242  0.99607849  0.91764712  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.07058824  0.48627454  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.32941177  0.99607849  0.99607849  0.65098041  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.54509807  0.99607849  0.9333334   0.22352943  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.82352948  0.98039222  0.99607849  0.65882355  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.94901967  0.99607849  0.93725497  0.22352943  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.34901962  0.98431379  0.9450981   0.33725491  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.01960784  0.80784321  0.96470594  0.6156863   0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.01568628  0.45882356  0.27058825  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "#mnist数据是55000张图片，每张图片是28*28 = 784像素\n",
    "print ('输入数据的shape:')\n",
    "print(mnist.train.images.shape) \n",
    "print('输入数据:') \n",
    "print (mnist.train.images)\n",
    "print('单张图片输入数据:') \n",
    "print (mnist.train.images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、设置模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters设置模型参数，该参数是确定模型训练方式的\n",
    "lr = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "\n",
    "n_inputs = 28   # MNIST data input (img shape: 28*28)28维\n",
    "n_steps = 28    # time steps28行，每次读一行数据训练\n",
    "n_hidden_units = 128   # neurons in hidden layer\n",
    "n_classes = 10      # MNIST classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、定义模型变量和参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in': <tf.Variable 'Variable:0' shape=(28, 128) dtype=float32_ref>, 'out': <tf.Variable 'Variable_1:0' shape=(128, 10) dtype=float32_ref>}\n",
      "{'in': <tf.Variable 'Variable_2:0' shape=(128,) dtype=float32_ref>, 'out': <tf.Variable 'Variable_3:0' shape=(10,) dtype=float32_ref>}\n"
     ]
    }
   ],
   "source": [
    "# tf Graph input，placehoder定义变量，hold住变量，在执行节点时传入数据给该变量\n",
    "x = tf.placeholder(tf.float32, [None, n_steps, n_inputs]) #none表示输入图片张数不确定\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "# 初始化参数，该参数在模型训练过程中会不断更新，最后达到最优\n",
    "weights = {\n",
    "    # 生成维度是(28, 128)的标准正太分布，mean=0，stddev=1\n",
    "    'in': tf.Variable(tf.random_normal([n_inputs, n_hidden_units])),\n",
    "    # (128, 10)\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_units, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    # (128, )\n",
    "    'in': tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ])),\n",
    "    # (10, )\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_classes, ]))\n",
    "}\n",
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、定义RNN神经单元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**补充知识：数据转换**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据在进入RNN前会做一定的变换，这里先以下面例子说明数据变换过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成一列数据\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "reshape(-1,2,2)函数的效果\n",
      "[[[ 0  1]\n",
      "  [ 2  3]]\n",
      "\n",
      " [[ 4  5]\n",
      "  [ 6  7]]\n",
      "\n",
      " [[ 8  9]\n",
      "  [10 11]]\n",
      "\n",
      " [[12 13]\n",
      "  [14 15]]\n",
      "\n",
      " [[16 17]\n",
      "  [18 19]]]\n",
      "b.shape: (5, 2, 2)\n",
      "reshape(-1,2)函数的效果\n",
      "[[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]\n",
      " [16 17]\n",
      " [18 19]]\n",
      "c.shape: (10, 2)\n"
     ]
    }
   ],
   "source": [
    "#从下面几个小实验中可以看到接下来几个函数的效果\n",
    "import numpy as np\n",
    "a= np.asarray(range(20))\n",
    "b = a.reshape(-1,2,2) #-1表示该维度数据没有被设置，函数会自行计算\n",
    "c = b.reshape(-1,2)\n",
    "print ('生成一列数据')\n",
    "print(a) \n",
    "print('reshape(-1,2,2)函数的效果') \n",
    "print(b) \n",
    "print('b.shape:',b.shape)\n",
    "print('reshape(-1,2)函数的效果') \n",
    "print(c) \n",
    "print('c.shape:',c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transpose函数的效果\n",
      "[[[ 0  1]\n",
      "  [ 4  5]\n",
      "  [ 8  9]\n",
      "  [12 13]\n",
      "  [16 17]]\n",
      "\n",
      " [[ 2  3]\n",
      "  [ 6  7]\n",
      "  [10 11]\n",
      "  [14 15]\n",
      "  [18 19]]]\n",
      "e.shape: (2, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "e = np.transpose(b,[1,0,2]) #三个数字分别代表三个维度的index\n",
    "print('transpose函数的效果') \n",
    "print(e)\n",
    "print('e.shape:',e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(X, weights, biases):\n",
    "    # 输入层\n",
    "    ########################################\n",
    "\n",
    "    # transpose the inputs shape from\n",
    "    # (128 batch ,28 steps, 28 inputs) ==> (128 batch * 28 steps, 28 inputs)\n",
    "    X = tf.reshape(X, [-1, n_inputs])\n",
    "\n",
    "    # into hidden\n",
    "    # X_in = (128 batch * 28 steps, 128 hidden)\n",
    "    X_in = tf.matmul(X, weights['in']) + biases['in']\n",
    "    # X_in ==> (128 batch, 28 steps, 128 hidden)\n",
    "    X_in = tf.reshape(X_in, [-1, n_steps, n_hidden_units])\n",
    "\n",
    "    # 隐藏层\n",
    "    ##########################################\n",
    "\n",
    "    # BasicLSTMCell定义单个cell\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(n_hidden\n",
    "    init_state = cell.zero_state(batch_size, dtype=tf.float32)\n",
    "    #dynamic_rnn函数将cell连成RNN 网络\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, X_in, initial_state=init_state)\n",
    "\n",
    "    # 输出层：输出logits\n",
    "    #############################################\n",
    "    #results = tf.matmul(final_state[1], weights['out']) + biases['out']\n",
    "    \n",
    "    # unpack to list [(batch, outputs)..] * steps\n",
    "    outputs = tf.unstack(tf.transpose(outputs, [1,0,2]))\n",
    "    results = tf.matmul([-1], weights['out']) + biases['out']    # shape = (128, 10),每张图片10个logit值\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6、定义损失函数、优化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**补充知识：tf.argmax函数**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.argmax是tensorflow使用numpy api实现的np.argmax，原理与np.argmax一致。函数使用方式有tf.argmax(array, 1)和tf.argmax(array, 0)，其中0/1是axis，axis是为了方便不同维度数据的计算，以下用例子说明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test = np.array([[1, 2, 3], [2, 3, 4], [5, 4, 3], [8, 7, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 当axis=0时，函数取各维度的最大值的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(test,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 当axis=1时，函数取各样本的最大值的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#损失函数是整个minibatch的目标类别和预测类别之间的交叉熵,\n",
    "pred = RNN(x, weights, biases)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7、输入数据，运行模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 accuracy: 0.210938\n",
      "step: 20 accuracy: 0.5\n",
      "step: 40 accuracy: 0.460938\n",
      "step: 60 accuracy: 0.53125\n",
      "step: 80 accuracy: 0.546875\n",
      "step: 100 accuracy: 0.546875\n",
      "step: 120 accuracy: 0.5625\n",
      "step: 140 accuracy: 0.546875\n",
      "step: 160 accuracy: 0.484375\n",
      "step: 180 accuracy: 0.53125\n",
      "step: 200 accuracy: 0.515625\n",
      "step: 220 accuracy: 0.664062\n",
      "step: 240 accuracy: 0.609375\n",
      "step: 260 accuracy: 0.585938\n",
      "step: 280 accuracy: 0.65625\n",
      "step: 300 accuracy: 0.5625\n",
      "step: 320 accuracy: 0.726562\n",
      "step: 340 accuracy: 0.585938\n",
      "step: 360 accuracy: 0.578125\n",
      "step: 380 accuracy: 0.65625\n",
      "step: 400 accuracy: 0.695312\n",
      "step: 420 accuracy: 0.648438\n",
      "step: 440 accuracy: 0.617188\n",
      "step: 460 accuracy: 0.53125\n",
      "step: 480 accuracy: 0.679688\n",
      "step: 500 accuracy: 0.648438\n",
      "step: 520 accuracy: 0.6875\n",
      "step: 540 accuracy: 0.640625\n",
      "step: 560 accuracy: 0.59375\n",
      "step: 580 accuracy: 0.734375\n",
      "step: 600 accuracy: 0.671875\n",
      "step: 620 accuracy: 0.671875\n",
      "step: 640 accuracy: 0.703125\n",
      "step: 660 accuracy: 0.578125\n",
      "step: 680 accuracy: 0.6875\n",
      "step: 700 accuracy: 0.734375\n",
      "step: 720 accuracy: 0.765625\n",
      "step: 740 accuracy: 0.773438\n",
      "step: 760 accuracy: 0.765625\n",
      "step: 780 accuracy: 0.640625\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # tf.initialize_all_variables() no long valid from\n",
    "    # 2017-03-02 if using tensorflow >= 0.12\n",
    "    if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "        init = tf.initialize_all_variables()\n",
    "    else:\n",
    "        init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape([batch_size, n_steps, n_inputs])\n",
    "        sess.run([train_op], feed_dict={\n",
    "            x: batch_xs,\n",
    "            y: batch_ys,\n",
    "        })\n",
    "        if step % 20 == 0:\n",
    "            print('step:',step,'accuracy:',sess.run(accuracy, feed_dict={\n",
    "            x: batch_xs,\n",
    "            y: batch_ys,\n",
    "            }))\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**参考文献**    \n",
    "例子：https://github.com/MorvanZhou/tutorials/tree/master/tensorflowTUT/tf20_RNN2   \n",
    "argmax：http://blog.csdn.net/qq575379110/article/details/70538051   \n",
    "数据转换：https://github.com/FanGhost/RNNStudy/blob/master/simpleRNN.ipynb    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
